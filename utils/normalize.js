const natural = require("natural");
const sw = require("stopword");

console.log("sw object:", sw);
console.log("sw.englishStopwords:", sw.englishStopwords);

const tokenizer = new natural.WordTokenizer();
const stemmer = natural.PorterStemmer;

const extraStopwords = [
  "explain",
  "describe",
  "write",
  "note",
  "short",
  "long",
  "answer",
  "what",
  "how",
  "why",
  "define",
  "discuss",
  "difference",
  "between",
  "analyze",
  "evaluate",
  "overview",
  "outline",
  "elaborate",
  "detailed",
  "mention",
  "with",
  "example",
  "illustrate",
  "need",
  "importance",
  "brief",
  "the",
  "is",
  "in",
  "on",
  "of",
  "to",
  "for",
  "and",
  "or",
  "a",
  "an",
  "about",
  "above",
  "across",
  "after",
  "against",
  "along",
  "among",
  "around",
  "at",
  "before",
  "behind",
  "below",
  "beneath",
  "beside",
  "besides",
  "between",
  "beyond",
  "but",
  "by",
  "concerning",
  "despite",
  "down",
  "during",
  "except",
  "following",
  "from",
  "given",
  "in front of",
  "inside",
  "instead of",
  "into",
  "like",
  "near",
  "next",
  "of",
  "off",
  "on account of",
  "onto",
  "out",
  "outside",
  "over",
  "past",
  "per",
  "prior to",
  "regarding",
  "since",
  "through",
  "throughout",
  "till",
  "to",
  "toward",
  "under",
  "underneath",
  "unlike",
  "until",
  "up",
  "upon",
  "versus",
  "via",
  "with",
  "within",
  "without",
  "according to",
  "as",
  "because",
  "although",
  "nor",
  "yet",
  "so",
  "if",
  "unless",
  "whether",
  "while",
  "whereas",
  "provided",
  "this",
  "that",
  "these",
  "those",
  "some",
  "any",
  "each",
  "every",
  "no",
  "not",
  "only",
  "just",
  "also",
  "even",
  "very",
  "too",
  "can",
  "could",
  "may",
  "might",
  "shall",
  "should",
  "will",
  "would",
  "do",
  "does",
  "did",
  "has",
  "have",
  "had",
  "be",
  "been",
  "being",
  "am",
  "are",
  "was",
  "were",
  "which",
  "who",
  "whom",
  "whose",
  "where",
  "when",
  "then",
  "there",
  "here",
  "now",
  "once",
  "ever",
  "never",
  "always",
  "often",
  "sometimes",
  "together",
  "apart",
  "towards",
  "throughout",
  "detail",
  "details",
  "please",
  "give",
  "list",
  "steps",
  "step",
  "provide",
  "show",
  "demonstrate",
  "state",
  "point",
  "out",
  "let",
  "us",
  "see",
  "look",
  "at",
  "into",
  "consider",
  "regarding",
  "concerning",
  "about",
  "related",
  "relating",
  "connection",
  "connected",
  "including",
  "included",
  "such",
  "as",
  "like",
  "similar",
  "than",
  "more",
  "less",
  "most",
  "least",
  "few",
  "many",
  "much",
  "little",
  "enough",
  "rather",
  "quite",
  "almost",
  "nearly",
  "approximately",
  "around",
  "close",
  "nearby",
  "far",
  "away",
  "back",
  "forward",
  "again",
  "else",
  "other",
  "another",
  "same",
  "different",
  "various",
  "several",
  "both",
  "either",
  "neither",
  "0",
  "i",
  "ii",
  "iii",
  "iv",
  "I",
  "II",
  "III",
  "IV",
  "1",
  "2",
  "3",
  "4",
  "5",
  "6",
  "7",
  "8",
  "9",
  "10",
  "unit",
  "topic",
  "chapter",
  "section",
  "part",
  "module",
  "lesson",
  "exercise",
  "activity",
  "task",
  "problem",
  "a",
  "b",
  "c",
  "d",
  "e",
  "f",
  "g",
  "h",
  "i",
  "j",
  "k",
  "l",
  "m",
  "n",
  "o",
  "p",
  "q",
  "r",
  "s",
  "t",
  "u",
  "v",
  "w",
  "x",
  "y",
  "z",
  "1",
  "2",
  "3",
  "4",
  "5",
  "6",
  "7",
  "8",
  "9",
  "10",
  "11",
  "12",
  "13",
  "14",
  "15",
  "16",
  "17",
  "18",
  "19",
  "20",
  "21",
  "22",
  "23",
  "24",
  "25",
  "26",
  "27",
  "28",
  "29",
  "30",
  "31",
  "32",
  "33",
  "34",
  "35",
  "36",
  "37",
  "38",
  "39",
  "40",
  "41",
  "42",
  "43",
  "44",
  "45",
  "46",
  "47",
  "48",
  "49",
  "50",
];
const englishStopwords = sw.englishStopwords || []; // Fallback to empty array if undefined
const customStopwords = [...new Set([...englishStopwords, ...extraStopwords])]; //  deduplicated merge

function normalizeQuestion(text) {
  text = text.toLowerCase();
  let tokens = tokenizer.tokenize(text);
  tokens = sw.removeStopwords(tokens, customStopwords); //  remove custom stopwords
  // tokens = tokens.map((token) => stemmer.stem(token)); //  apply stemming
  return tokens.join(" ");
}

module.exports = { normalizeQuestion };
